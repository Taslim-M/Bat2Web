{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "# from keras.models import Sequential, Model\n",
    "# from keras.layers import Dense, Dropout, Activation, Flatten, Convolution2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Convolution2D, MaxPooling2D, GlobalAveragePooling2D, Input,AveragePooling2D, BatchNormalization, LeakyReLU, SpatialDropout2D\n",
    "\n",
    "# from keras.applications import MobileNet\n",
    "# from keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import MobileNetV2, InceptionV3\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import recall_score,auc\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from collections import defaultdict,Counter\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from PIL import Image\n",
    "\n",
    "from kerastuner import HyperModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Loading and Preparation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSpeciesCode(x):\n",
    "    part = x.split('_')\n",
    "    if part[0] == 'ASETRI':\n",
    "        return 0\n",
    "    elif part[0] == 'EPTBOT':\n",
    "        return 1\n",
    "    elif part[0] == 'MYOEMA':\n",
    "        return 2\n",
    "    elif part[0] == 'PIPKUH':\n",
    "        return 3\n",
    "    elif part[0] == 'RHIMUS':\n",
    "        return 4\n",
    "    elif part[0] == 'RHYNAS':\n",
    "        return 5\n",
    "    elif part[0] == 'ROUAEG':\n",
    "        return 6\n",
    "    elif part[0] == 'TAPPER':\n",
    "        return 7\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "    \n",
    "def getSpecies(x):\n",
    "    if x == 0:\n",
    "        return 'A.tridens'\n",
    "    elif x == 1:\n",
    "        return 'E.bottae'\n",
    "    elif x == 2:\n",
    "        return 'M.emarginatus'\n",
    "    elif x == 3:\n",
    "        return 'P.kuhli'\n",
    "    elif x == 4:\n",
    "        return 'R.muscatellum'\n",
    "    elif x == 5:\n",
    "        return 'R.nasutus'\n",
    "    elif x == 6:\n",
    "        return 'R.aegyptius'\n",
    "    elif x == 7:\n",
    "        return 'T.perforatus'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "    \n",
    "    \n",
    "def generate_actual_predicted(Y_pred, X_test, Y_test): \n",
    "    predicted = list()\n",
    "    for i in range(len(Y_pred)):\n",
    "        predicted.append(np.argmax(Y_pred[i]))\n",
    "        \n",
    "    actual = list()\n",
    "    for i in range(len(Y_test)):\n",
    "        actual.append(np.argmax(Y_test[i]))\n",
    "        \n",
    "    return actual, predicted\n",
    "\n",
    "\n",
    "\n",
    "# Ytrain in Onehot encoded form \n",
    "def makeRandomOverSamples(X_train,Y_train):\n",
    "    \n",
    "    Y_train_labelled=[]\n",
    "    X_dims=X_train.shape\n",
    "\n",
    "    for i in range(len(Y_train)):\n",
    "        Y_train_labelled.append(np.argmax(Y_train[i]))\n",
    "\n",
    "    print('Original training set shape %s' %  [(getSpecies(k),v) for k,v in Counter(Y_train_labelled).items()])       \n",
    "    X_train= X_train.reshape(-1,X_dims[1]*X_dims[2]*X_dims[3])\n",
    "\n",
    "    ros = RandomOverSampler(random_state=123)\n",
    "    X_train, Y_train_labelled = ros.fit_resample(X_train, Y_train_labelled)\n",
    "\n",
    "\n",
    "    print('Resampled training set shape %s' % [(getSpecies(k),v) for k,v in Counter(Y_train_labelled).items()])\n",
    "\n",
    "\n",
    "    #reshape X_all\n",
    "    X_train= X_train.reshape(-1,X_dims[1],X_dims[2],X_dims[3])\n",
    "\n",
    "    # update Y_train\n",
    "    Y_train= np_utils.to_categorical(Y_train_labelled, num_classes=8)\n",
    "\n",
    "    print(\"After OverSampling\\nX_train: shape= \",X_train.shape)\n",
    "    print(\"Y_train: shape= \",Y_train.shape)\n",
    "\n",
    "    \n",
    "    \n",
    "    return(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_folder_path = '../../data/MFCC2'\n",
    "file_paths = [f for f in os.listdir(image_folder_path)]\n",
    "species = []\n",
    "for file_name in file_paths:\n",
    "    sp = file_name.split('_')\n",
    "    species.append(sp[0])\n",
    "\n",
    "df = pd.DataFrame(species, columns=['Species'])\n",
    "df['Species'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_all = []\n",
    "Y_all = []\n",
    "\n",
    "image_folder_path = '../../data/MFCC2'\n",
    "file_paths = [f for f in os.listdir(image_folder_path)]\n",
    "\n",
    "for file_name in file_paths:\n",
    "    spectrogram = Image.open(image_folder_path + '/' + file_name)\n",
    "    spectrogram = spectrogram.convert('RGB')\n",
    "    spectrogram = spectrogram.resize((170, 112))  \n",
    "    spectrogram = np.array(spectrogram)\n",
    "    #spectrogram = np.expand_dims(spectrogram, axis=2) \n",
    "    X_all.append(spectrogram)\n",
    "    Y_all.append(getSpeciesCode(file_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_all = np.array(X_all)\n",
    "Y_all = np.array(Y_all)\n",
    "\n",
    "print(X_all.shape)\n",
    "print(Y_all.shape)\n",
    "\n",
    "X_all = X_all.astype('float32')\n",
    "X_all /= 255\n",
    "\n",
    "Y_all = np_utils.to_categorical(Y_all, num_classes=8) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation: Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# onehot encoded Y_all\n",
    "def kFold_train(X_all,Y_all, mode_version):\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    n_split=10\n",
    "    n_classes=8\n",
    "\n",
    "    y_all_labelled=[]\n",
    "    for i in range(len(Y_all)):\n",
    "            y_all_labelled.append(np.argmax(Y_all[i]))\n",
    "\n",
    "    my_callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=20,verbose=1, mode='min',restore_best_weights=True)]\n",
    "\n",
    "    count = 1\n",
    "\n",
    "    for train_index,test_index in StratifiedKFold(n_split, shuffle=True, random_state=123).split(X_all,y_all_labelled):  \n",
    "        # use the index to generate training an testing sets\n",
    "        x_train,x_test=X_all[train_index],X_all[test_index]\n",
    "        y_train,y_test=Y_all[train_index],Y_all[test_index]\n",
    "        \n",
    "        \n",
    "       \n",
    "        x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state = 245, stratify=y_train)\n",
    "        x_train, y_train= makeRandomOverSamples(x_train, y_train)\n",
    "\n",
    "        # create and fit the model\n",
    "        cv_model=build_current_model() # lr,dense,cnn\n",
    "        history = cv_model.fit(x_train, y_train,\n",
    "                  batch_size=8,\n",
    "                  epochs=100,\n",
    "                  validation_data= (x_val, y_val),\n",
    "                  verbose=2,\n",
    "                  callbacks=my_callbacks)\n",
    "\n",
    "\n",
    "        file_name = mode_version +'_iter_' +str(count)\n",
    "        \n",
    "        \n",
    "                \n",
    "        #store test index\n",
    "#         csv_name= mode_version +'_testset_iter_' +str(count)\n",
    "#         test_index_df = pd.DataFrame(data=test_index,columns=[\"test_index\"])\n",
    "#         with open(csv_name, mode='w') as f:\n",
    "#                  test_index_df.to_csv(f)\n",
    "        #Store History\n",
    "        hist_df = pd.DataFrame(history.history) \n",
    "        hist_json_file = file_name + '.json'\n",
    "\n",
    "        with open(hist_json_file, mode='w') as f:\n",
    "            hist_df.to_json(f)\n",
    "            \n",
    "            \n",
    "\n",
    "        model_file = file_name + '.model'\n",
    "        print(model_file)\n",
    "\n",
    "        #Save Model\n",
    "        cv_model.save(model_file) #Save the model\n",
    "\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kFold_test(X_all,Y_all, mode_version):\n",
    "    from sklearn.metrics import precision_recall_fscore_support\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, auc, precision_recall_curve\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "\n",
    "    n_split=10\n",
    "    n_classes=8\n",
    "\n",
    "    all_base_precision = list()\n",
    "    all_base_recall = list()\n",
    "    all_macro_precision = list()\n",
    "    all_macro_recall = list()\n",
    "    all_f1 = list()\n",
    "    all_macro_f1 = list()\n",
    "\n",
    "    all_tpr = list()\n",
    "    all_fpr = list()\n",
    "    all_precision = list()\n",
    "    all_recall = list()\n",
    "    all_cm=list()\n",
    "    all_accuracy = list()\n",
    "\n",
    "    all_df = list()\n",
    "\n",
    "    y_all_labelled=[]\n",
    "    for i in range(len(Y_all)):\n",
    "            y_all_labelled.append(np.argmax(Y_all[i]))\n",
    "\n",
    "    count = 1\n",
    "\n",
    "\n",
    "    for train_index,test_index in StratifiedKFold(n_split, shuffle=True, random_state=123).split(X_all,y_all_labelled):  \n",
    "        # use the index to generate training an testing sets\n",
    "        x_train,_=X_all[train_index],X_all[test_index]\n",
    "        y_train,y_test=Y_all[train_index],Y_all[test_index]\n",
    "\n",
    "\n",
    "        file_name = mode_version +'_iter_' +str(count)\n",
    "#         csv_name= mode_version +'_testset_iter_' +str(count)\n",
    "        #Load History \n",
    "        hist_json_file = file_name + '.json'\n",
    "        history_info = pd.read_json(hist_json_file)\n",
    "        all_df.append(history_info)\n",
    "\n",
    "\n",
    "        # Load Model\n",
    "        model_file = file_name + '.model'\n",
    "        print('File Name Loaded: ',model_file)\n",
    "        cv_model = tf.keras.models.load_model(model_file) \n",
    "        \n",
    "#         #load test set \n",
    "#         testset_file= csv_name\n",
    "#         testset_df= pd.read_csv (testset_file)\n",
    "#         test_index=testset_df[\"test_index\"].to_numpy()\n",
    "       \n",
    "#         x_test=X_all[test_index]\n",
    "#         y_test=Y_all[test_index]\n",
    "\n",
    "\n",
    "        count+=1\n",
    "\n",
    "        #generate predictions\n",
    "        y_pred = cv_model.predict(x_test)\n",
    "        actual, predicted = generate_actual_predicted(y_pred, x_test, y_test)\n",
    "\n",
    "        #calc metrics\n",
    "        curr_base_prec, curr_base_rec, curr_f1, _ = precision_recall_fscore_support(actual, predicted)\n",
    "        curr_macro_prec = precision_score(actual, predicted,average='macro')\n",
    "        curr_macro_rec = recall_score(actual, predicted,average='macro')\n",
    "        curr_macro_f1 = f1_score(actual, predicted,average='macro')\n",
    "\n",
    "        actual_labeled = list()\n",
    "        predict_labeled = list()\n",
    "        for x,y in zip(actual,predicted):\n",
    "            actual_labeled.append(getSpecies(x))\n",
    "            predict_labeled.append(getSpecies(y))\n",
    "\n",
    "        labels = ['A.tridens','E.bottae','M.emarginatus','P.kuhli','R.muscatellum','R.nasutus', 'R.aegyptius', 'T.perforatus']\n",
    "        curr_cm=confusion_matrix(actual_labeled,predict_labeled,labels=labels)\n",
    "\n",
    "        curr_fpr = [0] * n_classes\n",
    "        curr_tpr = [0] * n_classes\n",
    "        for i in range(n_classes):\n",
    "            curr_fpr[i], curr_tpr[i], _ = roc_curve(y_test[:,i], y_pred[:,i])\n",
    "\n",
    "        curr_prec = [0] * n_classes\n",
    "        curr_rec = [0] * n_classes\n",
    "        for i in range(n_classes):\n",
    "            curr_prec[i], curr_rec[i], _ = precision_recall_curve(y_test[:,i], y_pred[:,i])\n",
    "\n",
    "\n",
    "        curr_accuracy = accuracy_score(actual, predicted)\n",
    "\n",
    "        #add to lists\n",
    "        all_base_precision.append(curr_base_prec)\n",
    "        all_base_recall.append(curr_base_rec)\n",
    "        all_macro_precision.append(curr_macro_prec)\n",
    "        all_macro_recall.append(curr_macro_rec)\n",
    "\n",
    "        all_f1.append(curr_f1)\n",
    "        all_macro_f1.append(curr_macro_f1)\n",
    "\n",
    "        all_accuracy.append(curr_accuracy)\n",
    "\n",
    "\n",
    "        all_fpr.append(curr_fpr)\n",
    "        all_tpr.append(curr_tpr)\n",
    "        all_precision.append(curr_prec)\n",
    "        all_recall.append(curr_rec)\n",
    "        all_cm.append(curr_cm)\n",
    "    kFold_metrics={\n",
    "            \"all_base_precision\": all_base_precision ,\n",
    "            \"all_base_recall\": all_base_recall,\n",
    "            \"all_macro_precision\":all_macro_precision ,\n",
    "            \"all_macro_recall\":all_macro_recall ,\n",
    "            \"all_f1\":all_f1,\n",
    "            \"all_macro_f1\":all_macro_f1 ,\n",
    "        \n",
    "            \"all_accuracy\":all_accuracy ,\n",
    "            \"all_fpr\":all_fpr,\n",
    "            \"all_tpr\": all_tpr,\n",
    "            \"all_precision\":all_precision,\n",
    "            \"all_recall\":all_recall,\n",
    "            \"all_cm\": all_cm,\n",
    "            \"all_df\":all_df\n",
    "            \n",
    "        }\n",
    "    return kFold_metrics\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_Accuracy(all_df):\n",
    "    for df in all_df:\n",
    "        _, axs = plt.subplots(ncols=2)\n",
    "\n",
    "        sns.lineplot(data=df['loss'],ax=axs[0], label='Training Loss', legend='brief')\n",
    "        sns.lineplot(data=df['val_loss'],ax=axs[0], label='Validation Loss', legend='brief')\n",
    "\n",
    "        sns.lineplot(data=df['acc'],ax=axs[1], label='Training Accuracy', legend='brief')\n",
    "        sns.lineplot(data=df['val_acc'],ax=axs[1], label='Validation Accuracy', legend='brief')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(KFold_metrics):\n",
    "    print('precision mean by class', np.array(KFold_metrics.get(\"all_base_precision\")).mean(axis=0))\n",
    "    print('precision sdev by class', np.array(KFold_metrics.get(\"all_base_precision\")).std(axis=0))\n",
    "\n",
    "    print('macro precision mean', np.array(KFold_metrics.get(\"all_macro_precision\")).mean())\n",
    "    print('macro precision sdev', np.array(KFold_metrics.get(\"all_macro_precision\")).std())\n",
    "\n",
    "\n",
    "    print('recall mean', np.array(KFold_metrics.get(\"all_base_recall\")).mean(axis=0))\n",
    "    print('recall sdev', np.array(KFold_metrics.get(\"all_base_recall\")).std(axis=0))\n",
    "\n",
    "    print('macro recall mean', np.array(KFold_metrics.get(\"all_macro_recall\")).mean())\n",
    "    print('macro recall sdev', np.array(KFold_metrics.get(\"all_macro_recall\")).std())\n",
    "\n",
    "    print('f1 mean', np.array(KFold_metrics.get(\"all_f1\")).mean(axis=0))\n",
    "    print('f1 sdev', np.array(KFold_metrics.get(\"all_f1\")).std(axis=0))\n",
    "\n",
    "    print('macro f1 mean', np.array(KFold_metrics.get(\"all_macro_f1\")).mean())\n",
    "    print('macro f1 sdev', np.array(KFold_metrics.get(\"all_macro_f1\")).std())\n",
    "\n",
    "    print('accuracy mean', np.array(KFold_metrics.get(\"all_accuracy\")).mean())\n",
    "    print('accuracy sdev', np.array(KFold_metrics.get(\"all_accuracy\")).std())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all K-Fold ROC curves\n",
    "def plot_ROC(all_fpr,all_tpr,n_split=10, n_classes=8):\n",
    "    for i in range(n_split):\n",
    "        _, axs = plt.subplots(ncols=1)\n",
    "        axs.set(xlabel='False Positive Rate',ylabel='True Positive Rate', title='ROC Curve K-Fold#'+str(i+1))\n",
    "        for j in range(n_classes):\n",
    "            auc_val = auc(all_fpr[i][j], all_tpr[i][j])\n",
    "            auc_val = np.around(auc_val,4)\n",
    "            sns.lineplot(x=all_fpr[i][j],y=all_tpr[i][j],ax=axs, label='Class '+ getSpecies(j) +' (area = ' + str(auc_val) + ')', legend='brief')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_meanAUC(all_fpr,all_tpr,n_split=10, n_classes=8):\n",
    "    aucs = list()\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        aucs.append(list())\n",
    "\n",
    "\n",
    "    for i in range(n_split):\n",
    "        for j in range(n_classes):\n",
    "            auc_val = auc(all_fpr[i][j], all_tpr[i][j])\n",
    "            aucs[j].append(auc_val)\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        print(\"Sp: \", getSpecies(i))\n",
    "        print(\"AUC Mean \", np.array(aucs[i]).mean())\n",
    "        print(\"Std \", np.array(aucs[i]).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot all K-Fold Precision/Recall curves\n",
    "def plot_precision_recall(all_recall,all_precision,n_split=10, n_classes=8):\n",
    "    for i in range(n_split):\n",
    "        _, axs = plt.subplots(ncols=1)\n",
    "        axs.set(xlabel='Recall',ylabel='Precision', title='Precision/Recall Curve K-Fold#'+str(i+1))\n",
    "        for j in range(n_classes):\n",
    "            sns.lineplot(x=all_recall[i][j],y=all_precision[i][j],ax=axs, label='Class '+ getSpecies(j), legend='brief')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrices_per_iter(all_cm,n_split=10, n_classes=8):\n",
    "    ## Plot all K-Fold confusion matrices\n",
    "    import numpy as np\n",
    "    import matplotlib.pylab as pl\n",
    "    import matplotlib.gridspec as gridspec\n",
    "    from matplotlib import pyplot as plt\n",
    "    labels = ['A.tridens','E.bottae','M.emarginatus','P.kuhli','R.muscatellum','R.nasutus', 'R.aegyptius', 'T.perforatus']\n",
    "        \n",
    "    # Create 1X 5 sub plots\n",
    "    # gs = gridspec.GridSpec(1,n_split)\n",
    "    figs=[]\n",
    "    for i in range(n_split):\n",
    "        figs.append(plt.figure())\n",
    "\n",
    "    for i in range(n_split):\n",
    "        print('Confusion Matrix K-Fold #'+ str(i+1)+\"\\n\")\n",
    "        print(all_cm[i])\n",
    "        print(\"\\n\")\n",
    "\n",
    "        ax=figs[i].add_subplot()\n",
    "        sns.heatmap(all_cm[i], annot=True, ax = ax); #annot=True to annotate cells\n",
    "\n",
    "\n",
    "        # labels, title and ticks\n",
    "        ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "        ax.set_title('Confusion Matrix K-Fold #'+ str(i+1)); \n",
    "        ax.xaxis.set_ticklabels(labels,rotation=45); ax.yaxis.set_ticklabels(labels,rotation=45);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  plot_macro_confusion_matrices(all_cm,n_split=10, n_classes=8):\n",
    "    ## plot macro cm\n",
    "    labels = ['A.tridens','E.bottae','M.emarginatus','P.kuhli','R.muscatellum','R.nasutus', 'R.aegyptius', 'T.perforatus']\n",
    "        \n",
    "    sum_all_cm=np.zeros((n_classes,n_classes)).astype('int64')\n",
    "    for i in range(n_split):\n",
    "        sum_all_cm+=all_cm[i]\n",
    "\n",
    "\n",
    "    #plot \n",
    "    figs=[]\n",
    "    for i in range(2):\n",
    "        figs.append(plt.figure())\n",
    "\n",
    "    print(\"sum of all confuion matrices\\n\",sum_all_cm)\n",
    "    ax=figs[0].add_subplot()\n",
    "    sns.heatmap(sum_all_cm, annot=True, ax = ax);\n",
    "\n",
    "    avg_all_cm=np.divide(sum_all_cm,n_split).astype('int64')\n",
    "    print(\"\\naverage of all confuion matrices\\n\",avg_all_cm)\n",
    "    ax=figs[1].add_subplot()\n",
    "    sns.heatmap(avg_all_cm, annot=True, ax = ax);\n",
    "    return sum_all_cm, avg_all_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def plot_normalised_confusion_matrix( sum_all_cm, avg_all_cm, n_split=10, n_classes=8):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    labels = ['A.tridens','E.bottae','M.emarginatus','P.kuhli','R.muscatellum','R.nasutus', 'R.aegyptius', 'T.perforatus']\n",
    "        \n",
    "\n",
    "    cm= sum_all_cm/ sum_all_cm.astype(np.float).sum(axis=1,keepdims = True)\n",
    "    cm = (np.around(cm,2))\n",
    "    print(cm)\n",
    "\n",
    "\n",
    "    labels = ['A.tridens','E.bottae','M.emarginatus','P.kuhli','R.muscatellum','R.nasutus', 'R.aegyptius', 'T.perforatus']\n",
    "\n",
    "\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells\n",
    "\n",
    "    # labels, title and ticks\n",
    "    ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "    ax.set_title('Confusion Matrix'); \n",
    "    ax.xaxis.set_ticklabels(labels,rotation=45); ax.yaxis.set_ticklabels(labels,rotation=45);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## V1 !!!!! K-Fold Training and Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/spec_smote_v1\n"
     ]
    }
   ],
   "source": [
    "folder = \"models\"\n",
    "mode_version = \"spec_RO_v1\"\n",
    "mode_version = os.path.join(folder, mode_version)\n",
    "\n",
    "print(mode_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_current_model():\n",
    "    inp = Input(shape=(112,170,3))\n",
    "    lay = Convolution2D(filters=16,kernel_size=(7,7),strides=(2,2),padding='same')(inp)\n",
    "    lay = BatchNormalization()(lay)\n",
    "    lay = Activation('relu')(lay)\n",
    "    lay = MaxPooling2D(pool_size=(2,2),strides=2,padding='same')(lay)\n",
    "    lay = SpatialDropout2D(0.06)(lay)\n",
    "\n",
    "    lay = Convolution2D(filters=64,kernel_size=(5,5),strides=(2,2),padding='same')(lay)\n",
    "    lay = BatchNormalization()(lay)\n",
    "    lay = Activation('relu')(lay)\n",
    "    lay = AveragePooling2D(pool_size=(2,2),strides=2,padding='same')(lay)\n",
    "    lay = SpatialDropout2D(0.06)(lay)\n",
    "\n",
    "    lay = Convolution2D(filters=112,kernel_size=(3,3),strides=(1,1),padding='same')(lay)\n",
    "    lay = BatchNormalization()(lay)\n",
    "    lay = Activation('relu')(lay)\n",
    "    lay = AveragePooling2D(pool_size=(2,2),strides=2,padding='same')(lay)\n",
    "    lay = SpatialDropout2D(0.02)(lay)\n",
    "\n",
    "    lay = Convolution2D(filters=64,kernel_size=(3,3),strides=(1,1),padding='same')(lay)\n",
    "    lay = BatchNormalization()(lay)\n",
    "    lay = Activation('relu')(lay)\n",
    "    lay = AveragePooling2D(pool_size=(2,2),strides=2,padding='same')(lay)\n",
    "    lay = SpatialDropout2D(0.02)(lay)\n",
    "\n",
    "    lay = Flatten()(lay)\n",
    "\n",
    "    lay = Dense(80)(lay)\n",
    "    lay = BatchNormalization()(lay)\n",
    "    lay = Activation('relu')(lay)\n",
    "    lay = Dropout(0.15)(lay)\n",
    "    \n",
    "    lay = Dense(96)(lay)\n",
    "    lay = BatchNormalization()(lay)\n",
    "    lay = Activation('relu')(lay)\n",
    "    lay = Dropout(0.15)(lay)\n",
    "    \n",
    "    lay = Dense(32)(lay)\n",
    "    lay = BatchNormalization()(lay)\n",
    "    lay = Activation('relu')(lay)\n",
    "    lay = Dropout(0.15)(lay)\n",
    "\n",
    "    x_out = Dense(8, name='output', activation='softmax')(lay)\n",
    "    model = Model(inputs=inp, outputs=x_out)\n",
    "    model.compile(\n",
    "        optimizer=Adam(lr=0.003),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = build_current_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kFold_train(X_all,Y_all, mode_version)\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kFold_metrics=kFold_test(X_all,Y_all, mode_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_df=[]\n",
    "# for i in range(10):\n",
    "    \n",
    "#      #Load History \n",
    "#         hist_json_file =  mode_version +'_iter_' +str(i+1) + '.json'\n",
    "#         history_info = pd.read_json(hist_json_file)\n",
    "#         all_df.append(history_info)\n",
    "# print (all_df[99])\n",
    "# plot_loss_Accuracy(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(KFold_metrics.get(\"all_df\"))\n",
    "plot_loss_Accuracy(kFold_metrics.get(\"all_df\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(kFold_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ROC(kFold_metrics.get(\"all_fpr\"),kFold_metrics.get(\"all_tpr\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_meanAUC (kFold_metrics.get(\"all_fpr\"),kFold_metrics.get(\"all_tpr\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_precision_recall(kFold_metrics.get(\"all_recall\"),kFold_metrics.get(\"all_precision\"))\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrices_per_iter(kFold_metrics.get(\"all_cm\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sum_all_cm, avg_all_cm=plot_macro_confusion_matrices(kFold_metrics.get(\"all_cm\"))                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_normalised_confusion_matrix(sum_all_cm, avg_all_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> V2 !!!!! K-Fold Training and Evaluation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/spec_smote_v1\n"
     ]
    }
   ],
   "source": [
    "folder = \"models\"\n",
    "mode_version = \"spec_RO_v2\"\n",
    "mode_version = os.path.join(folder, mode_version)\n",
    "\n",
    "print(mode_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_current_model():\n",
    "    inp = Input(shape=(112,170,3))\n",
    "    lay = Convolution2D(filters=24,kernel_size=(5,5),strides=(2,2),padding='same')(inp)\n",
    "    lay = BatchNormalization()(lay)\n",
    "    lay = Activation('relu')(lay)\n",
    "    lay = MaxPooling2D(pool_size=(2,2),strides=2,padding='same')(lay)\n",
    "    lay = SpatialDropout2D(0.06)(lay)\n",
    "\n",
    "    lay = Convolution2D(filters=56,kernel_size=(5,5),strides=(2,2),padding='same')(lay)\n",
    "    lay = BatchNormalization()(lay)\n",
    "    lay = Activation('relu')(lay)\n",
    "    lay = AveragePooling2D(pool_size=(2,2),strides=2,padding='same')(lay)\n",
    "    lay = SpatialDropout2D(0.06)(lay)\n",
    "\n",
    "    lay = Convolution2D(filters=136,kernel_size=(7,7),strides=(1,1),padding='same')(lay)\n",
    "    lay = BatchNormalization()(lay)\n",
    "    lay = Activation('relu')(lay)\n",
    "    lay = AveragePooling2D(pool_size=(2,2),strides=2,padding='same')(lay)\n",
    "    lay = SpatialDropout2D(0.02)(lay)\n",
    "\n",
    "    lay = Convolution2D(filters=120,kernel_size=(5,5),strides=(1,1),padding='same')(lay)\n",
    "    lay = BatchNormalization()(lay)\n",
    "    lay = Activation('relu')(lay)\n",
    "    lay = AveragePooling2D(pool_size=(2,2),strides=2,padding='same')(lay)\n",
    "    lay = SpatialDropout2D(0.02)(lay)\n",
    "\n",
    "    lay = Flatten()(lay)\n",
    "\n",
    "    lay = Dense(512)(lay)\n",
    "    lay = BatchNormalization()(lay)\n",
    "    lay = Activation('relu')(lay)\n",
    "    lay = Dropout(0.4)(lay)\n",
    "\n",
    "    lay = Dense(256)(lay)\n",
    "    lay = BatchNormalization()(lay)\n",
    "    lay = Activation('relu')(lay)\n",
    "    lay = Dropout(0.3)(lay)\n",
    "\n",
    "    lay = Dense(128)(lay)\n",
    "    lay = BatchNormalization()(lay)\n",
    "    lay = Activation('relu')(lay)\n",
    "    lay = Dropout(0.2)(lay)\n",
    "\n",
    "    x_out = Dense(8, name='output', activation='softmax')(lay)\n",
    "    model = Model(inputs=inp, outputs=x_out)\n",
    "    model.compile(\n",
    "        optimizer=Adam(lr=0.003),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_current_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kFold_train(X_all,Y_all, mode_version)\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kFold_metrics=kFold_test(X_all,Y_all, mode_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(KFold_metrics.get(\"all_df\"))\n",
    "plot_loss_Accuracy(kFold_metrics.get(\"all_df\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(kFold_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ROC(kFold_metrics.get(\"all_fpr\"),kFold_metrics.get(\"all_tpr\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_meanAUC (kFold_metrics.get(\"all_fpr\"),kFold_metrics.get(\"all_tpr\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_precision_recall(kFold_metrics.get(\"all_recall\"),kFold_metrics.get(\"all_precision\"))\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrices_per_iter(kFold_metrics.get(\"all_cm\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sum_all_cm, avg_all_cm=plot_macro_confusion_matrices(kFold_metrics.get(\"all_cm\"))                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_normalised_confusion_matrix(sum_all_cm, avg_all_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> V3 !!!!! K-Fold Training and Evaluation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"models\"\n",
    "mode_version = \"spec_RO_v3\"\n",
    "mode_version = os.path.join(folder, mode_version)\n",
    "\n",
    "print(mode_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_current_model():\n",
    "    inp = Input(shape=(112,170,3))\n",
    "    lay = Convolution2D(filters=176,kernel_size=(7,7),strides=(2,2),padding='same')(inp)\n",
    "    lay = BatchNormalization()(lay)\n",
    "    lay = Activation('relu')(lay)\n",
    "    lay = MaxPooling2D(pool_size=(2,2),strides=2,padding='same')(lay)\n",
    "    lay = SpatialDropout2D(0.06)(lay)\n",
    "\n",
    "    lay = Convolution2D(filters=48,kernel_size=(5,5),strides=(2,2),padding='same')(lay)\n",
    "    lay = BatchNormalization()(lay)\n",
    "    lay = Activation('relu')(lay)\n",
    "    lay = AveragePooling2D(pool_size=(2,2),strides=2,padding='same')(lay)\n",
    "    lay = SpatialDropout2D(0.06)(lay)\n",
    "\n",
    "    lay = Convolution2D(filters=144,kernel_size=(3,3),strides=(1,1),padding='same')(lay)\n",
    "    lay = BatchNormalization()(lay)\n",
    "    lay = Activation('relu')(lay)\n",
    "    lay = AveragePooling2D(pool_size=(2,2),strides=2,padding='same')(lay)\n",
    "    lay = SpatialDropout2D(0.02)(lay)\n",
    "\n",
    "    lay = Convolution2D(filters=192,kernel_size=(3,3),strides=(1,1),padding='same')(lay)\n",
    "    lay = BatchNormalization()(lay)\n",
    "    lay = Activation('relu')(lay)\n",
    "    lay = AveragePooling2D(pool_size=(2,2),strides=2,padding='same')(lay)\n",
    "    lay = SpatialDropout2D(0.02)(lay)\n",
    "\n",
    "    lay = Flatten()(lay)\n",
    "\n",
    "    lay = Dense(144)(lay)\n",
    "    lay = BatchNormalization()(lay)\n",
    "    lay = Activation('relu')(lay)\n",
    "    lay = Dropout(0.15)(lay)\n",
    "    \n",
    "    lay = Dense(80)(lay)\n",
    "    lay = BatchNormalization()(lay)\n",
    "    lay = Activation('relu')(lay)\n",
    "    lay = Dropout(0.15)(lay)\n",
    "    \n",
    "    lay = Dense(96)(lay)\n",
    "    lay = BatchNormalization()(lay)\n",
    "    lay = Activation('relu')(lay)\n",
    "    lay = Dropout(0.15)(lay)\n",
    "\n",
    "    x_out = Dense(8, name='output', activation='softmax')(lay)\n",
    "    model = Model(inputs=inp, outputs=x_out)\n",
    "    model.compile(\n",
    "        optimizer=Adam(lr=0.003),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_current_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kFold_train(X_all,Y_all, mode_version)\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kFold_metrics=kFold_test(X_all,Y_all, mode_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(KFold_metrics.get(\"all_df\"))\n",
    "plot_loss_Accuracy(kFold_metrics.get(\"all_df\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(kFold_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ROC(kFold_metrics.get(\"all_fpr\"),kFold_metrics.get(\"all_tpr\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_meanAUC (kFold_metrics.get(\"all_fpr\"),kFold_metrics.get(\"all_tpr\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_precision_recall(kFold_metrics.get(\"all_recall\"),kFold_metrics.get(\"all_precision\"))\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrices_per_iter(kFold_metrics.get(\"all_cm\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sum_all_cm, avg_all_cm=plot_macro_confusion_matrices(kFold_metrics.get(\"all_cm\"))                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_normalised_confusion_matrix(sum_all_cm, avg_all_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> V4 !!!!! K-Fold Training and Evaluation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"models\"\n",
    "mode_version = \"spec_RO_v4\"\n",
    "mode_version = os.path.join(folder, mode_version)\n",
    "\n",
    "print(mode_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_current_model():\n",
    "    inp = Input(shape=(112,170,3))\n",
    "    lay = Convolution2D(filters=160,kernel_size=(7,7),strides=(2,2),padding='same')(inp)\n",
    "    lay = BatchNormalization()(lay)\n",
    "    lay = Activation('relu')(lay)\n",
    "    lay = MaxPooling2D(pool_size=(2,2),strides=2,padding='same')(lay)\n",
    "    lay = SpatialDropout2D(0.06)(lay)\n",
    "\n",
    "    lay = Convolution2D(filters=112,kernel_size=(5,5),strides=(2,2),padding='same')(lay)\n",
    "    lay = BatchNormalization()(lay)\n",
    "    lay = Activation('relu')(lay)\n",
    "    lay = AveragePooling2D(pool_size=(2,2),strides=2,padding='same')(lay)\n",
    "    lay = SpatialDropout2D(0.06)(lay)\n",
    "\n",
    "    lay = Convolution2D(filters=80,kernel_size=(3,3),strides=(1,1),padding='same')(lay)\n",
    "    lay = BatchNormalization()(lay)\n",
    "    lay = Activation('relu')(lay)\n",
    "    lay = AveragePooling2D(pool_size=(2,2),strides=2,padding='same')(lay)\n",
    "    lay = SpatialDropout2D(0.02)(lay)\n",
    "\n",
    "    lay = Convolution2D(filters=64,kernel_size=(3,3),strides=(1,1),padding='same')(lay)\n",
    "    lay = BatchNormalization()(lay)\n",
    "    lay = Activation('relu')(lay)\n",
    "    lay = AveragePooling2D(pool_size=(2,2),strides=2,padding='same')(lay)\n",
    "    lay = SpatialDropout2D(0.02)(lay)\n",
    "\n",
    "    lay = Flatten()(lay)\n",
    "\n",
    "    lay = Dense(256)(lay)\n",
    "    lay = BatchNormalization()(lay)\n",
    "    lay = Activation('relu')(lay)\n",
    "    lay = Dropout(0.15)(lay)\n",
    "    \n",
    "    lay = Dense(448)(lay)\n",
    "    lay = BatchNormalization()(lay)\n",
    "    lay = Activation('relu')(lay)\n",
    "    lay = Dropout(0.15)(lay)\n",
    "    \n",
    "    lay = Dense(352)(lay)\n",
    "    lay = BatchNormalization()(lay)\n",
    "    lay = Activation('relu')(lay)\n",
    "    lay = Dropout(0.15)(lay)\n",
    "\n",
    "    x_out = Dense(8, name='output', activation='softmax')(lay)\n",
    "    model = Model(inputs=inp, outputs=x_out)\n",
    "    model.compile(\n",
    "        optimizer=Adam(lr=0.003),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_current_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kFold_train(X_all,Y_all, mode_version)\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kFold_metrics=kFold_test(X_all,Y_all, mode_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(KFold_metrics.get(\"all_df\"))\n",
    "plot_loss_Accuracy(kFold_metrics.get(\"all_df\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(kFold_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ROC(kFold_metrics.get(\"all_fpr\"),kFold_metrics.get(\"all_tpr\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_meanAUC (kFold_metrics.get(\"all_fpr\"),kFold_metrics.get(\"all_tpr\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_precision_recall(kFold_metrics.get(\"all_recall\"),kFold_metrics.get(\"all_precision\"))\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrices_per_iter(kFold_metrics.get(\"all_cm\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sum_all_cm, avg_all_cm=plot_macro_confusion_matrices(kFold_metrics.get(\"all_cm\"))                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_normalised_confusion_matrix(sum_all_cm, avg_all_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> V5 !!!!! K-Fold Training and Evaluation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"models\"\n",
    "mode_version = \"spec_RO_v5\"\n",
    "mode_version = os.path.join(folder, mode_version)\n",
    "\n",
    "print(mode_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_current_model():\n",
    "    inp = Input(shape=(112,170,3))\n",
    "    lay = Convolution2D(filters=48,kernel_size=(7,7),strides=(2,2),padding='same')(inp)\n",
    "    lay = BatchNormalization()(lay)\n",
    "    lay = Activation('relu')(lay)\n",
    "    lay = MaxPooling2D(pool_size=(2,2),strides=2,padding='same')(lay)\n",
    "    lay = SpatialDropout2D(0.06)(lay)\n",
    "\n",
    "    lay = Convolution2D(filters=32,kernel_size=(5,5),strides=(2,2),padding='same')(lay)\n",
    "    lay = BatchNormalization()(lay)\n",
    "    lay = Activation('relu')(lay)\n",
    "    lay = AveragePooling2D(pool_size=(2,2),strides=2,padding='same')(lay)\n",
    "    lay = SpatialDropout2D(0.06)(lay)\n",
    "\n",
    "    lay = Convolution2D(filters=48,kernel_size=(3,3),strides=(1,1),padding='same')(lay)\n",
    "    lay = BatchNormalization()(lay)\n",
    "    lay = Activation('relu')(lay)\n",
    "    lay = AveragePooling2D(pool_size=(2,2),strides=2,padding='same')(lay)\n",
    "    lay = SpatialDropout2D(0.02)(lay)\n",
    "\n",
    "    lay = Convolution2D(filters=128,kernel_size=(3,3),strides=(1,1),padding='same')(lay)\n",
    "    lay = BatchNormalization()(lay)\n",
    "    lay = Activation('relu')(lay)\n",
    "    lay = AveragePooling2D(pool_size=(2,2),strides=2,padding='same')(lay)\n",
    "    lay = SpatialDropout2D(0.02)(lay)\n",
    "\n",
    "    lay = Flatten()(lay)\n",
    "\n",
    "    lay = Dense(112)(lay)\n",
    "    lay = BatchNormalization()(lay)\n",
    "    lay = Activation('relu')(lay)\n",
    "    lay = Dropout(0.15)(lay)\n",
    "    \n",
    "    lay = Dense(32)(lay)\n",
    "    lay = BatchNormalization()(lay)\n",
    "    lay = Activation('relu')(lay)\n",
    "    lay = Dropout(0.15)(lay)\n",
    "\n",
    "    x_out = Dense(8, name='output', activation='softmax')(lay)\n",
    "    model = Model(inputs=inp, outputs=x_out)\n",
    "    model.compile(\n",
    "        optimizer=Adam(lr=0.003),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_current_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kFold_train(X_all,Y_all, mode_version)\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kFold_metrics=kFold_test(X_all,Y_all, mode_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(KFold_metrics.get(\"all_df\"))\n",
    "plot_loss_Accuracy(kFold_metrics.get(\"all_df\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(kFold_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ROC(kFold_metrics.get(\"all_fpr\"),kFold_metrics.get(\"all_tpr\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_meanAUC (kFold_metrics.get(\"all_fpr\"),kFold_metrics.get(\"all_tpr\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_precision_recall(kFold_metrics.get(\"all_recall\"),kFold_metrics.get(\"all_precision\"))\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrices_per_iter(kFold_metrics.get(\"all_cm\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sum_all_cm, avg_all_cm=plot_macro_confusion_matrices(kFold_metrics.get(\"all_cm\"))                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_normalised_confusion_matrix(sum_all_cm, avg_all_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V6 Re-Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"models\"\n",
    "mode_version = \"spec_RO_v6\"\n",
    "mode_version = os.path.join(folder, mode_version)\n",
    "\n",
    "print(mode_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = []\n",
    "Y_all = []\n",
    "\n",
    "image_folder_path = '../../data/MFCC2'\n",
    "file_paths = [f for f in os.listdir(image_folder_path)]\n",
    "\n",
    "for file_name in file_paths:\n",
    "    spectrogram = Image.open(image_folder_path + '/' + file_name)\n",
    "    spectrogram = spectrogram.convert('RGB')\n",
    "    spectrogram = spectrogram.resize((85, 56))  \n",
    "    spectrogram = np.array(spectrogram)\n",
    "    #spectrogram = np.expand_dims(spectrogram, axis=2) \n",
    "    X_all.append(spectrogram)\n",
    "    Y_all.append(getSpeciesCode(file_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3018, 56, 85, 3)\n",
      "(3018,)\n"
     ]
    }
   ],
   "source": [
    "X_all = np.array(X_all)\n",
    "Y_all = np.array(Y_all)\n",
    "\n",
    "print(X_all.shape)\n",
    "print(Y_all.shape)\n",
    "\n",
    "X_all = X_all.astype('float32')\n",
    "X_all /= 255\n",
    "\n",
    "Y_all = np_utils.to_categorical(Y_all, num_classes=8) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_current_model():\n",
    "    inp = Input(shape=(56,85,3))\n",
    "    lay = Convolution2D(filters=168,kernel_size=(7,7),strides=(2,2),padding='same')(inp)\n",
    "    lay = BatchNormalization()(lay)\n",
    "    lay = Activation('relu')(lay)\n",
    "    lay = MaxPooling2D(pool_size=(2,2),strides=2,padding='same')(lay)\n",
    "    lay = Dropout(0.2)(lay)\n",
    "\n",
    "    lay = Convolution2D(filters=56,kernel_size=(7,7),strides=(2,2),padding='same')(lay)\n",
    "    lay = BatchNormalization()(lay)\n",
    "    lay = Activation('relu')(lay)\n",
    "    lay = AveragePooling2D(pool_size=(2,2),strides=2,padding='same')(lay)\n",
    "    lay = Dropout(0.3)(lay)\n",
    "\n",
    "    lay = Convolution2D(filters=232,kernel_size=(5,5),strides=(1,1),padding='same')(lay)\n",
    "    lay = BatchNormalization()(lay)\n",
    "    lay = Activation('relu')(lay)\n",
    "    lay = AveragePooling2D(pool_size=(2,2),strides=2,padding='same')(lay)\n",
    "    lay = Dropout(0.3)(lay)\n",
    "\n",
    "    lay = Convolution2D(filters=104,kernel_size=(5,5),strides=(1,1),padding='same')(lay)\n",
    "    lay = BatchNormalization()(lay)\n",
    "    lay = Activation('relu')(lay)\n",
    "    lay = AveragePooling2D(pool_size=(2,2),strides=2,padding='same')(lay)\n",
    "    lay = Dropout(0.4)(lay)\n",
    "\n",
    "    lay = Flatten()(lay)\n",
    "\n",
    "    x_out = Dense(8, name='output', activation='softmax')(lay)\n",
    "    model = Model(inputs=inp, outputs=x_out)\n",
    "    model.compile(\n",
    "        optimizer=Adam(lr=0.003),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_current_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kFold_train(X_all,Y_all, mode_version)\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kFold_metrics=kFold_test(X_all,Y_all, mode_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(KFold_metrics.get(\"all_df\"))\n",
    "plot_loss_Accuracy(kFold_metrics.get(\"all_df\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(kFold_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ROC(kFold_metrics.get(\"all_fpr\"),kFold_metrics.get(\"all_tpr\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_meanAUC (kFold_metrics.get(\"all_fpr\"),kFold_metrics.get(\"all_tpr\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_precision_recall(kFold_metrics.get(\"all_recall\"),kFold_metrics.get(\"all_precision\"))\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrices_per_iter(kFold_metrics.get(\"all_cm\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sum_all_cm, avg_all_cm=plot_macro_confusion_matrices(kFold_metrics.get(\"all_cm\"))                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_normalised_confusion_matrix(sum_all_cm, avg_all_cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "291.97px",
    "left": "759.445px",
    "right": "20px",
    "top": "97.9716px",
    "width": "366.345px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
