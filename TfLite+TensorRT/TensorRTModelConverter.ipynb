{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"mel_smote_v1_iter_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 112, 170, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 56, 85, 56)        8288      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 56, 85, 56)        224       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 56, 85, 56)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 28, 43, 56)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 28, 43, 56)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 22, 72)        100872    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 14, 22, 72)        288       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 14, 22, 72)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_3 (Average (None, 7, 11, 72)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 7, 11, 72)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 7, 11, 56)         36344     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 7, 11, 56)         224       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 7, 11, 56)         0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_4 (Average (None, 4, 6, 56)          0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 4, 6, 56)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 4, 6, 72)          36360     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 4, 6, 72)          288       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 4, 6, 72)          0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_5 (Average (None, 2, 3, 72)          0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 2, 3, 72)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 432)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 48)                20784     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 48)                192       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 8)                 392       \n",
      "=================================================================\n",
      "Total params: 204,256\n",
      "Trainable params: 203,648\n",
      "Non-trainable params: 608\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Linked TensorRT version: (7, 1, 3)\n",
      "INFO:tensorflow:Loaded TensorRT version: (7, 1, 3)\n",
      "INFO:tensorflow:Could not find TRTEngineOp_0_0 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Assets written to: mel22oct/assets\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "input_saved_model_dir = \"mel_smote_v1_iter_1.model\"\n",
    "output_saved_model_dir = \"mel22oct\"\n",
    "converter = trt.TrtGraphConverterV2(input_saved_model_dir=input_saved_model_dir)\n",
    "converter.convert()\n",
    "converter.save(output_saved_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_loaded = tf.saved_model.load(output_saved_model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'max_batch_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-250bf1183fd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m converter = trt.TrtGraphConverterV2(input_saved_model_dir=input_saved_model_dir,\n\u001b[0;32m---> 12\u001b[0;31m     conversion_params=conversion_params, max_batch_size =1)\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmy_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'max_batch_size'"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "\n",
    "input_saved_model_dir = \"mel_smote_v1_iter_1.model\"\n",
    "output_saved_model_dir = \"mel22oct_nvidia\"\n",
    "\n",
    "conversion_params = trt.DEFAULT_TRT_CONVERSION_PARAMS\n",
    "conversion_params = conversion_params._replace(max_workspace_size_bytes=(1<<32))\n",
    "conversion_params = conversion_params._replace(precision_mode=\"FP16\")\n",
    "conversion_params = conversion_params._replace(maximum_cached_engines=1)\n",
    "\n",
    "converter = trt.TrtGraphConverterV2(input_saved_model_dir=input_saved_model_dir,\n",
    "    conversion_params=conversion_params, max_batch_size =1)\n",
    "converter.convert()\n",
    "def my_input_fn():\n",
    "    for _ in range(1):\n",
    "        Inp1 = np.random.normal(size=(8,112,170,3)).astype(np.float32)\n",
    "#         inp2 = np.random.normal(size=(1, 112, 170, 3)).astype(np.float32)\n",
    "        yield Inp1\n",
    "\n",
    "    \n",
    "converter.build(input_fn=my_input_fn)\n",
    "converter.save(output_saved_model_dir)\n",
    "\n",
    "saved_model_loaded = tf.saved_model.load(output_saved_model_dir, tags=[tag_constants.SERVING])\n",
    "graph_func = saved_model_loaded.signatures[signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
    "frozen_func = convert_to_constants.convert_variables_to_constants_v2(graph_func)\n",
    "output = frozen_func(input_data)[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to TF-TRT FP32...\n",
      "INFO:tensorflow:Linked TensorRT version: (7, 1, 3)\n",
      "INFO:tensorflow:Loaded TensorRT version: (7, 1, 3)\n",
      "INFO:tensorflow:Could not find TRTEngineOp_16_0 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Assets written to: mel_collab/assets\n",
      "Done Converting to TF-TRT FP32\n"
     ]
    }
   ],
   "source": [
    "print('Converting to TF-TRT FP32...')\n",
    "conversion_params = trt.DEFAULT_TRT_CONVERSION_PARAMS._replace(precision_mode=trt.TrtPrecisionMode.FP32,\n",
    "                                                               max_workspace_size_bytes=8000000000)\n",
    "\n",
    "input_saved_model_dir = \"mel_smote_v1_iter_1.model\"\n",
    "converter = trt.TrtGraphConverterV2(input_saved_model_dir=input_saved_model_dir,\n",
    "                                    conversion_params=conversion_params)\n",
    "converter.convert()\n",
    "converter.save(output_saved_model_dir='mel_collab')\n",
    "print('Done Converting to TF-TRT FP32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version:  2.3.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensorflow version: \", tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tftrt(input_saved_model):\n",
    "    \"\"\"Runs prediction on a single image and shows the result.\n",
    "    input_saved_model (string): Name of the input model stored in the current dir\n",
    "    \"\"\"\n",
    "    img_path = './testIMG.png'  # Siberian_husky\n",
    "    img = image.load_img(img_path, target_size=(112, 170))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    #x = preprocess_input(x)\n",
    "    x = tf.constant(x)\n",
    "    \n",
    "    saved_model_loaded = tf.saved_model.load(input_saved_model)\n",
    "    signature_keys = list(saved_model_loaded.signatures.keys())\n",
    "    print(signature_keys)\n",
    "\n",
    "    infer = saved_model_loaded.signatures['serving_default']\n",
    "    print(infer.structured_outputs)\n",
    "\n",
    "    labeling = infer(x)\n",
    "    preds = labeling['probs'].numpy()\n",
    "    print('{} - Predicted: {}'.format(img_path, decode_predictions(preds, top=3)[0]))\n",
    "    plt.subplot(2,2,1)\n",
    "    plt.imshow(img);\n",
    "    plt.axis('off');\n",
    "    #plt.title(decode_predictions(preds, top=3)[0][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['serving_default']\n",
      "{'output': TensorSpec(shape=<unknown>, dtype=tf.float32, name='output')}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'probs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5c0b1f79289f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict_tftrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mel_collab'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-26826033e523>\u001b[0m in \u001b[0;36mpredict_tftrt\u001b[0;34m(input_saved_model)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mlabeling\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabeling\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'probs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} - Predicted: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'probs'"
     ]
    }
   ],
   "source": [
    "predict_tftrt('mel_collab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the final evaluation that worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_saved_model = 'mel_collab'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['serving_default']\n",
      "{'output': TensorSpec(shape=<unknown>, dtype=tf.float32, name='output')}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Runs prediction on a single image and shows the result.\n",
    "input_saved_model (string): Name of the input model stored in the current dir\n",
    "\"\"\"\n",
    "img_path = './ROUA_sam.png'  # Siberian_husky\n",
    "img = image.load_img(img_path, target_size=(112, 170))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "#x = preprocess_input(x)\n",
    "x = tf.constant(x)\n",
    "\n",
    "saved_model_loaded = tf.saved_model.load(input_saved_model)\n",
    "signature_keys = list(saved_model_loaded.signatures.keys())\n",
    "print(signature_keys)\n",
    "\n",
    "infer = saved_model_loaded.signatures['serving_default']\n",
    "print(infer.structured_outputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeling = infer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['output'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeling.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 1. 0. 0. 0.]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-d05f7a5a8e6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#print('{} - Predicted: {}'.format(img_path, decode_predictions(preds, top=3)[0]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "preds = labeling['output'].numpy()\n",
    "print(preds)\n",
    "#print('{} - Predicted: {}'.format(img_path, decode_predictions(preds, top=3)[0]))\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(img);\n",
    "plt.axis('off');\n",
    "#plt.title(decode_predictions(preds, top=3)[0][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
