{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Loading and Preparation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSpeciesCode(x):\n",
    "    part = x.split('_')\n",
    "    if part[0] == 'ASETRI':\n",
    "        return 0\n",
    "    elif part[0] == 'EPTBOT':\n",
    "        return 1\n",
    "    elif part[0] == 'MYOEMA':\n",
    "        return 2\n",
    "    elif part[0] == 'PIPKUH':\n",
    "        return 3\n",
    "    elif part[0] == 'RHIMUS':\n",
    "        return 4\n",
    "    elif part[0] == 'RHYNAS':\n",
    "        return 5\n",
    "    elif part[0] == 'ROUAEG':\n",
    "        return 6\n",
    "    elif part[0] == 'TAPPER':\n",
    "        return 7\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "    \n",
    "def getSpecies(x):\n",
    "    if x == 0:\n",
    "        return 'A.tridens'\n",
    "    elif x == 1:\n",
    "        return 'E.bottae'\n",
    "    elif x == 2:\n",
    "        return 'M.emarginatus'\n",
    "    elif x == 3:\n",
    "        return 'P.kuhli'\n",
    "    elif x == 4:\n",
    "        return 'R.muscatellum'\n",
    "    elif x == 5:\n",
    "        return 'R.nasutus'\n",
    "    elif x == 6:\n",
    "        return 'R.aegyptius'\n",
    "    elif x == 7:\n",
    "        return 'T.perforatus'\n",
    "    elif x == 8:\n",
    "        return 'No_Bat'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "    \n",
    "    \n",
    "def generate_actual_predicted(Y_pred, X_test, Y_test): \n",
    "    predicted = list()\n",
    "    for i in range(len(Y_pred)):\n",
    "        predicted.append(np.argmax(Y_pred[i]))\n",
    "        \n",
    "    actual = list()\n",
    "    for i in range(len(Y_test)):\n",
    "        actual.append(np.argmax(Y_test[i]))\n",
    "        \n",
    "    return actual, predicted\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "from numpy import expand_dims\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy import asarray\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RHIMUS    1665\n",
       "TAPPER     403\n",
       "PIPKUH     299\n",
       "RHYNAS     269\n",
       "EPTBOT     124\n",
       "ROUAEG     121\n",
       "MYOEMA     112\n",
       "ASETRI      25\n",
       "Name: Species, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_folder_path = '../../data/SpectogramInitial'\n",
    "file_paths = [f for f in os.listdir(image_folder_path)]\n",
    "species = []\n",
    "for file_name in file_paths:\n",
    "    sp = file_name.split('_')\n",
    "    species.append(sp[0])\n",
    "\n",
    "df = pd.DataFrame(species, columns=['Species'])\n",
    "df['Species'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_all = []\n",
    "Y_all = []\n",
    "\n",
    "image_folder_path = '../../data/SpectogramInitial'\n",
    "file_paths = [f for f in os.listdir(image_folder_path)]\n",
    "\n",
    "for file_name in file_paths:\n",
    "    spectrogram = Image.open(image_folder_path + '/' + file_name)\n",
    "#     spectrogram = spectrogram.convert('RGB')\n",
    "#     spectrogram = spectrogram.resize((168, 112))  \n",
    "    \n",
    "    spectrogram = spectrogram.convert('L')\n",
    "    spectrogram = spectrogram.resize((28, 28))  \n",
    "    \n",
    "    spectrogram = np.array(spectrogram)\n",
    "    #spectrogram = np.expand_dims(spectrogram, axis=2) \n",
    "    X_all.append(spectrogram)\n",
    "    Y_all.append(getSpeciesCode(file_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc9fc483e10>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_all[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Noise\n",
    "image_folder_path = '../../data/noise'\n",
    "file_paths = [f for f in os.listdir(image_folder_path)]\n",
    "\n",
    "for file_name in file_paths:\n",
    "    spectrogram = Image.open(image_folder_path + '/' + file_name)\n",
    "#     spectrogram = spectrogram.convert('RGB')\n",
    "#     spectrogram = spectrogram.resize((168, 112))\n",
    "    spectrogram = spectrogram.convert('L')\n",
    "    spectrogram = spectrogram.resize((28, 28))  \n",
    "    spectrogram = np.array(spectrogram)\n",
    "    #spectrogram = np.expand_dims(spectrogram, axis=2) \n",
    "    X_all.append(spectrogram)\n",
    "    Y_all.append(8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3426, 1, 28, 28)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all = np.array(X_all)\n",
    "X_all = np.expand_dims(X_all, axis=1) #Only for GreyScale\n",
    "X_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3426, 1, 28, 28)\n",
      "(3426,)\n"
     ]
    }
   ],
   "source": [
    "X_all = np.array(X_all)\n",
    "Y_all = np.array(Y_all)\n",
    "\n",
    "#X_all = np.moveaxis(X_all, -1, 1) #For pytorch if RGB\n",
    "\n",
    "Y_all = Y_all.astype(int)\n",
    "\n",
    "print(X_all.shape)\n",
    "print(Y_all.shape)\n",
    "\n",
    "X_all = X_all.astype('float32')\n",
    "X_all = (X_all - 127.5) / 127.5\n",
    "\n",
    "#Y_all = np_utils.to_categorical(Y_all, num_classes=9) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2740,)\n"
     ]
    }
   ],
   "source": [
    "# train /test= 80/20% split\n",
    "# Data is stratified\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_all, Y_all, test_size=0.2, random_state = 245, stratify=Y_all)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_x_train = torch.from_numpy(X_train) # transform to torch tensor\n",
    "tensor_y_train = torch.from_numpy(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2740, 1, 28, 28])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2740])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_x_test =  torch.from_numpy(X_test) \n",
    "tensor_y_test =  torch.from_numpy(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([686, 1, 28, 28])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_y_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset  = TensorDataset(tensor_x_train,tensor_y_train) # create your datset\n",
    "testset  = TensorDataset(tensor_x_test,tensor_y_test) # create your datset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Param and Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "batch_size = 32\n",
    "keep_prob = 1 # 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=trainset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(dataset=testset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Model Definition and Training </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/team9/anaconda3/envs/gpu/lib/python3.7/site-packages/ipykernel_launcher.py:32: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (3): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (fc1): Linear(in_features=2048, out_features=625, bias=True)\n",
       "  (layer4): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=625, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (fc2): Linear(in_features=625, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # L1 ImgIn shape=(?, 28, 28, 1)\n",
    "        #    Conv     -> (?, 28, 28, 32)\n",
    "        #    Pool     -> (?, 14, 14, 32)\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            torch.nn.Dropout(p=1 - keep_prob))\n",
    "        # L2 ImgIn shape=(?, 14, 14, 32)\n",
    "        #    Conv      ->(?, 14, 14, 64)\n",
    "        #    Pool      ->(?, 7, 7, 64)\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            torch.nn.Dropout(p=1 - keep_prob))\n",
    "        # L3 ImgIn shape=(?, 7, 7, 64)\n",
    "        #    Conv      ->(?, 7, 7, 128)\n",
    "        #    Pool      ->(?, 4, 4, 128)\n",
    "        self.layer3 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=1),\n",
    "            torch.nn.Dropout(p=1 - keep_prob))\n",
    "\n",
    "        # L4 FC 4x4x128 inputs -> 625 outputs\n",
    "        self.fc1 = torch.nn.Linear(4 * 4 * 128, 625, bias=True)\n",
    "        torch.nn.init.xavier_uniform(self.fc1.weight)\n",
    "        self.layer4 = torch.nn.Sequential(\n",
    "            self.fc1,\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(p=1 - keep_prob))\n",
    "        # L5 Final FC 625 inputs -> 10 outputs\n",
    "        self.fc2 = torch.nn.Linear(625, 10, bias=True)\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight) # initialize parameters\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0), -1)   # Flatten them for FC\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# instantiate CNN model\n",
    "model = CNN()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 3, 3])\n",
      "torch.Size([32])\n",
      "torch.Size([64, 32, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([128, 64, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([625, 2048])\n",
      "torch.Size([625])\n",
      "torch.Size([10, 625])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "learning_rate = 0.001\n",
    "criterion = torch.nn.CrossEntropyLoss()    # Softmax is internally computed.\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Deep Learning network ...\n",
      "Epoch= 1,\t batch = 0,\t cost = 2.3232,\t accuracy = 0.0\n",
      "[Epoch:    1], averaged cost = 58.1539955\n",
      "Epoch= 2,\t batch = 0,\t cost = 0.6859,\t accuracy = 0.78125\n",
      "[Epoch:    2], averaged cost = 38.6307678\n",
      "Epoch= 3,\t batch = 0,\t cost = 0.4967,\t accuracy = 0.84375\n",
      "[Epoch:    3], averaged cost = 27.9277554\n",
      "Epoch= 4,\t batch = 0,\t cost = 0.2451,\t accuracy = 0.90625\n",
      "[Epoch:    4], averaged cost = 20.1776524\n",
      "Epoch= 5,\t batch = 0,\t cost = 0.1216,\t accuracy = 0.96875\n",
      "[Epoch:    5], averaged cost = 16.1923275\n",
      "Epoch= 6,\t batch = 0,\t cost = 0.1518,\t accuracy = 0.9375\n",
      "[Epoch:    6], averaged cost = 13.5239391\n",
      "Epoch= 7,\t batch = 0,\t cost = 0.0770,\t accuracy = 0.96875\n",
      "[Epoch:    7], averaged cost = 11.0124378\n",
      "Epoch= 8,\t batch = 0,\t cost = 0.0810,\t accuracy = 0.96875\n",
      "[Epoch:    8], averaged cost = 10.0719252\n",
      "Epoch= 9,\t batch = 0,\t cost = 0.0713,\t accuracy = 0.96875\n",
      "[Epoch:    9], averaged cost = 8.49437046\n",
      "Epoch= 10,\t batch = 0,\t cost = 0.0281,\t accuracy = 1.0\n",
      "[Epoch:   10], averaged cost = 7.69693708\n",
      "Epoch= 11,\t batch = 0,\t cost = 0.0245,\t accuracy = 1.0\n",
      "[Epoch:   11], averaged cost = 6.21951675\n",
      "Epoch= 12,\t batch = 0,\t cost = 0.0086,\t accuracy = 1.0\n",
      "[Epoch:   12], averaged cost = 5.46911573\n",
      "Epoch= 13,\t batch = 0,\t cost = 0.0117,\t accuracy = 1.0\n",
      "[Epoch:   13], averaged cost = 5.26074934\n",
      "Epoch= 14,\t batch = 0,\t cost = 0.0047,\t accuracy = 1.0\n",
      "[Epoch:   14], averaged cost = 4.32674742\n",
      "Epoch= 15,\t batch = 0,\t cost = 0.0094,\t accuracy = 1.0\n",
      "[Epoch:   15], averaged cost = 4.85768461\n",
      "Learning Finished!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'argmax' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-3759cf591941>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Learning Finished!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m#  _, argmax = torch.max(outputs, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0margmax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'argmax' is not defined"
     ]
    }
   ],
   "source": [
    "print('Training the Deep Learning network ...')\n",
    "train_cost = []\n",
    "train_accu = []\n",
    "\n",
    "training_epochs = 15\n",
    "total_batch = len(train_loader) // batch_size\n",
    "\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    for i, (batch_X, batch_Y) in enumerate(train_loader):\n",
    "        X = Variable(batch_X)    # image is already size of (28x28), no reshape\n",
    "        Y = Variable(batch_Y)    # label is not one-hot encoded\n",
    "\n",
    "        optimizer.zero_grad() # <= initialization of the gradients\n",
    "        \n",
    "        # forward propagation\n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, Y) # <= compute the loss function\n",
    "        \n",
    "        # Backward propagation\n",
    "        cost.backward() # <= compute the gradient of the loss/cost function     \n",
    "        optimizer.step() # <= Update the gradients\n",
    "             \n",
    "        # Print some performance to monitor the training\n",
    "        prediction = hypothesis.data.max(dim=1)[1]\n",
    "        train_accu.append(((prediction.data == Y.data).float().mean()).item())\n",
    "        train_cost.append(cost.item())   \n",
    "        if i % 200 == 0:\n",
    "            print(\"Epoch= {},\\t batch = {},\\t cost = {:2.4f},\\t accuracy = {}\".format(epoch+1, i, train_cost[-1], train_accu[-1]))\n",
    "       \n",
    "        avg_cost += cost.data / total_batch\n",
    "\n",
    "    print(\"[Epoch: {:>4}], averaged cost = {:>.9}\".format(epoch + 1, avg_cost.item()))\n",
    "\n",
    "\n",
    "print('Learning Finished!')\n",
    "#  _, argmax = torch.max(outputs, 1)\n",
    "accuracy = (labels == argmax.squeeze()).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
